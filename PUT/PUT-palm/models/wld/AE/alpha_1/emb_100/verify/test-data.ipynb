{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 96, 160, 1)]      0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 48, 80, 16)        160       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 40, 32)        4640      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 12, 20, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 6, 10, 128)        73856     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 3, 5, 256)         295168    \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3840)              0         \n",
      "_________________________________________________________________\n",
      "latent_vector (Dense)        (None, 50)                192050    \n",
      "=================================================================\n",
      "Total params: 584,370\n",
      "Trainable params: 584,370\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.models import Model\n",
    "model = load_model('../model/epoch_058.hdf5')\n",
    "encoder_model = Model(inputs=model.input, outputs=model.layers[7].output)\n",
    "\n",
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 95, 125)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "all_feats = np.load('../../../../../../data/palm_all_wld_aug_feats.npy')\n",
    "all_feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 394, 522)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "all_feats = np.load('../../../../../../data/palm_all_mc_aug_feats.npy')\n",
    "all_feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 394, 522)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "all_feats = np.load('../../../../../../data/palm_all_imgs_aug_prep.npy')\n",
    "all_feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 236, 313)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "all_feats = np.load('../../../../../../../PUT-wrist/data/palm_all_rlt_aug_feats.npy')\n",
    "all_feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 384, 512, 1)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 192, 256, 16)      160       \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 96, 128, 32)       4640      \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 48, 64, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 24, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 12, 16, 256)       295168    \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 49152)             0         \n",
      "_________________________________________________________________\n",
      "latent_vector (Dense)        (None, 1000)              49153000  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 49152)             49201152  \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 12, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_12 (Conv2DT (None, 24, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_13 (Conv2DT (None, 48, 64, 128)       295040    \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_14 (Conv2DT (None, 96, 128, 64)       73792     \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_15 (Conv2DT (None, 192, 256, 32)      18464     \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_16 (Conv2DT (None, 384, 512, 16)      4624      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_17 (Conv2DT (None, 384, 512, 1)       145       \n",
      "_________________________________________________________________\n",
      "decoder_output (Activation)  (None, 384, 512, 1)       0         \n",
      "=================================================================\n",
      "Total params: 99,728,617\n",
      "Trainable params: 99,728,617\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Activation, Dense, Input, Dropout, BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, Flatten\n",
    "from tensorflow.keras.layers import Reshape, Conv2DTranspose\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping , CSVLogger, ReduceLROnPlateau\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(1994)\n",
    "\n",
    "# Network parameters\n",
    "#390, 682\n",
    "input_shape = (96, 128, 1)#95, 125\n",
    "input_shape = (224, 320, 1)#236, 313\n",
    "input_shape = (384, 512, 1)#394,522\n",
    "batch_size = 128\n",
    "kernel_size = 3\n",
    "latent_dim = 1000\n",
    "# Encoder/Decoder number of CNN layers and filters per layer\n",
    "layer_filters = [16, 32, 64,128,256]\n",
    "\n",
    "\n",
    "def my_loss(y_true, y_pred):\n",
    "    MSE = K.sum(K.square(y_pred - y_true), axis=-1)\n",
    "    MAE = K.sum(K.abs(y_pred - y_true), axis=-1)\n",
    "    return MSE + 0.2 * MAE\n",
    "\n",
    "\n",
    "# Build the Autoencoder Model\n",
    "def getModel():\n",
    "    # First build the Encoder Model\n",
    "    inputs = Input(shape=input_shape, name='encoder_input')\n",
    "    x = inputs\n",
    "    # Stack of Conv2D blocks\n",
    "    # Notes:\n",
    "    # 1) Use Batch Normalization before ReLU on deep networks\n",
    "    # 2) Use MaxPooling2D as alternative to strides>1\n",
    "    # - faster but not as good as strides>1\n",
    "    for filters in layer_filters:\n",
    "        x = Conv2D(filters=filters,\n",
    "                   kernel_size=kernel_size,\n",
    "                   strides=2,\n",
    "                   activation='relu',\n",
    "                   padding='same')(x)\n",
    "\n",
    "    # Shape info needed to build Decoder Model\n",
    "    shape = K.int_shape(x)\n",
    "\n",
    "    # Generate the latent vector\n",
    "    x = Flatten()(x)\n",
    "    latent = Dense(latent_dim, activation='relu', name='latent_vector')(x)\n",
    "\n",
    "#     # Instantiate Encoder Model\n",
    "#     encoder = Model(inputs, latent, name='encoder')\n",
    "#     encoder.summary()\n",
    "#\n",
    "#     # Build the Decoder Model\n",
    "#     latent_inputs = Input(shape=(latent_dim,), name='decoder_input')\n",
    "#    x = Dense(shape[1] * shape[2] * shape[3])(latent_inputs)\n",
    "    \n",
    "    x = Dense(shape[1] * shape[2] * shape[3], activation='relu')(latent)\n",
    "    x = Reshape((shape[1], shape[2], shape[3]))(x)\n",
    "\n",
    "    # Stack of Transposed Conv2D blocks\n",
    "    # Notes:\n",
    "    # 1) Use Batch Normalization before ReLU on deep networks\n",
    "    # 2) Use UpSampling2D as alternative to strides>1\n",
    "    # - faster but not as good as strides>1\n",
    "    for filters in layer_filters[::-1]:\n",
    "        x = Conv2DTranspose(filters=filters,\n",
    "                            kernel_size=kernel_size,\n",
    "                            strides=2,\n",
    "                            activation='relu',\n",
    "                            padding='same')(x)\n",
    "\n",
    "    x = Conv2DTranspose(filters=1,\n",
    "                        kernel_size=kernel_size,\n",
    "                        padding='same')(x)\n",
    "\n",
    "    outputs = Activation('sigmoid', name='decoder_output')(x)\n",
    "    \n",
    "\n",
    "    # Instantiate Decoder Model\n",
    "    model = Model(inputs, outputs, name='decoder')\n",
    "    \n",
    "    optim=Adam(lr=1e-3, decay=0.0)\n",
    "    model.compile(loss = \"binary_crossentropy\",#[my_loss, ssim_loss], loss_weights = [1, 0.075],#'mse'\n",
    "                  optimizer = optim,\n",
    "                  metrics   = [metrics.mse,\n",
    "                               metrics.mae\n",
    "                               ])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "gmodel = getModel()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
